{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a virtual environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "python3 -m venv <your-venv-name>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Activate the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source ~/<your-venv-name>/bin/activate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install git+https://github.com/huggingface/diffusers.git"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clone the HF repo and install jax and flax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "git clone https://github.com/huggingface/community-events\n",
    "cd community-events/jax-controlnet-sprint/training_scripts\n",
    "pip install -U -r requirements_flax.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verify that jax was installed properly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "jax.device_count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install logging "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install wandb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wget https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/controlnet_training/conditioning_image_1.png\n",
    "wget https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/controlnet_training/conditioning_image_2.png"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Log in to Hugging Face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "huggingface-cli login"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set the environmental variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "export MODEL_DIR=\"runwayml/stable-diffusion-v1-5\"\n",
    "export OUTPUT_DIR=\"runs/fill-circle-{timestamp}\"\n",
    "export HUB_MODEL_ID=\"controlnet-fill-circle\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "python3 train_controlnet_flax.py \\\n",
    " --pretrained_model_name_or_path=$MODEL_DIR \\\n",
    " --output_dir=$OUTPUT_DIR \\\n",
    " --dataset_name=fusing/fill50k \\\n",
    " --resolution=512 \\\n",
    " --learning_rate=1e-5 \\\n",
    " --validation_image \"./conditioning_image_1.png\" \"./conditioning_image_2.png\" \\\n",
    " --validation_prompt \"red circle with blue background\" \"cyan circle with brown floral background\" \\\n",
    " --validation_steps=1000 \\\n",
    " --train_batch_size=2 \\\n",
    " --revision=\"non-ema\" \\\n",
    " --from_pt \\\n",
    " --report_to=\"wandb\" \\\n",
    " --tracker_project_name=$HUB_MODEL_ID \\\n",
    " --num_train_epochs=11 \\\n",
    " --push_to_hub \\\n",
    " --hub_model_id=$HUB_MODEL_ID"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " --checkpointing_steps=500"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can start training from checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " --controlnet_model_name_or_path=\"./control_out/500\" "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is recommended to set --snr_gamma to 5.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Profile the code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " --profile_steps==5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To inspect profile trace, run following code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install tensorflow tensorboard-plugin-profile\n",
    "tensorboard --logdir runs/fill-circle-100steps-20230411_165612/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Killing the TPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kill -9 PID"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pushing model to HUB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_pretrained(\"path_to_your_model_repository\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import create_repo, upload_folder\n",
    "\n",
    "create_repo(\"username/my-awesome-model\")\n",
    "upload_folder(\n",
    "    folder_path=\"path_to_your_model_repository\",\n",
    "    repo_id=\"username/my-awesome-model\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating the space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "\n",
    "# inference function takes prompt, negative prompt and image\n",
    "def infer(prompt, negative_prompt, image):\n",
    "    # implement your inference function here\n",
    "    return output_image\n",
    "\n",
    "# you need to pass inputs and outputs according to inference function\n",
    "gr.Interface(fn = infer, inputs = [\"text\", \"text\", \"image\"], outputs = \"image\").launch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Customize the space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = \"Animal Pose controlnet\"\n",
    "description = \"This is a demo on ControlNet based on canny filter.\"\n",
    "# you need to pass your examples according to your inputs\n",
    "# each inner list is one example, each element in the list corresponding to a component in the `inputs`.\n",
    "examples = [[\"a cat with cake texture\", \"low quality\", \"cat_image.png\"]]\n",
    "gr.Interface(fn = infer, inputs = [\"text\", \"text\", \"image\"], outputs = \"image\",\n",
    "            title = title, description = description, examples = examples, theme='gradio/soft').launch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using Blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "\n",
    "def infer_segmentation(prompt, negative_prompt, image):\n",
    "    # your inference function for segmentation control \n",
    "    return im\n",
    "\n",
    "def infer_canny(prompt, negative_prompt, image):\n",
    "    # your inference function for canny control \n",
    "    return im\n",
    "\n",
    "with gr.Blocks(theme='gradio/soft') as demo:\n",
    "    gr.Markdown(\"## Stable Diffusion with Different Controls\")\n",
    "    gr.Markdown(\"In this app, you can find different ControlNets with different filters. \")\n",
    "\n",
    "\n",
    "    with gr.Tab(\"ControlNet on Canny Filter \"):\n",
    "        prompt_input_canny = gr.Textbox(label=\"Prompt\")\n",
    "        negative_prompt_canny = gr.Textbox(label=\"Negative Prompt\")\n",
    "        canny_input = gr.Image(label=\"Input Image\")\n",
    "        canny_output = gr.Image(label=\"Output Image\")\n",
    "        submit_btn = gr.Button(value = \"Submit\")\n",
    "        canny_inputs = [prompt_input_canny, negative_prompt_canny, canny_input]\n",
    "        submit_btn.click(fn=infer_canny, inputs=canny_inputs, outputs=[canny_output])\n",
    "        \n",
    "    with gr.Tab(\"ControlNet with Semantic Segmentation\"):\n",
    "        prompt_input_seg = gr.Textbox(label=\"Prompt\")\n",
    "        negative_prompt_seg = gr.Textbox(label=\"Negative Prompt\")\n",
    "        seg_input = gr.Image(label=\"Image\")\n",
    "        seg_output = gr.Image(label=\"Output Image\")\n",
    "        submit_btn = gr.Button(value = \"Submit\")\n",
    "        seg_inputs = [prompt_input_seg, negative_prompt_seg, seg_input]\n",
    "        submit_btn.click(fn=infer_segmentation, inputs=seg_inputs, outputs=[seg_output])\n",
    "\n",
    "demo.launch()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
